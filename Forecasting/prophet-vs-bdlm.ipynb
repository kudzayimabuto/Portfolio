{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fbProphet Vs to baysian dynamic linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Linear Models (DLMs) or state space models\n",
    "The __pydlm__ package implementes the Bayesian dynamic linear model (Harrison and West, 1999) for time series data analysis. Modeling and fitting is simple and easy with pydlm. Complex models can be constructed via simple operations.Define a very general class of non-stationary time series models. Basicaly the model used Kalman filters to estimate the different state matrices.A dynamic linear model can handle non-stationary processes, missing values and non-uniform sampling as well as observations with varying accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install bdlm package \n",
    "pip install pydlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#import Packages\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "import os\n",
    "import gc\n",
    "from pydlm import dlm, trend, seasonality, autoReg\n",
    "#use multiple processing in code\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reduction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data an prepare the forecast DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv'))\n",
    "calendar = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv'))\n",
    "sell_prices = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sell_prices.csv'))\n",
    "\n",
    "sell_prices['id'] = sell_prices.item_id+'_'+ sell_prices.store_id+'_validation'\n",
    "ex_columns = ['item_id','dept_id','cat_id','store_id','state_id']\n",
    "sales_train_validation = reduce_mem_usage(sales_train_validation.drop(ex_columns, axis = 1))\n",
    "sales_train = reduce_mem_usage(sales_train_validation.melt(id_vars=[\"id\"], \n",
    "        var_name=\"d\", \n",
    "        value_name=\"sales_units\"))\n",
    "\n",
    "\n",
    "day_d = reduce_mem_usage(calendar[['date','d','wm_yr_wk']])\n",
    "sales_date = reduce_mem_usage(sales_train.merge(day_d, on = 'd', how = 'left'))\n",
    "sell_prices = reduce_mem_usage(sell_prices[['id','sell_price','wm_yr_wk']])\n",
    "\n",
    "df_final = reduce_mem_usage(sales_date.merge(sell_prices, on=['id','wm_yr_wk'], how = 'left'))\n",
    "df_final['y'] = df_final['sales_units']\n",
    "\n",
    "#df_final = df_final[df_final['y']>=1]\n",
    "df_final['y'] = df_final['y']+1\n",
    "x_trans, lamb = boxcox(df_final['y'])\n",
    "df_final['y'] = x_trans\n",
    "\n",
    "#create holidays data frame\n",
    "\n",
    "event_name = calendar[['event_name_1','date']].dropna(axis = 0)\n",
    "event_name.columns = ['holiday','ds']\n",
    "event_name['lower_window'] = 0\n",
    "event_name['upper_window'] = 1\n",
    "#reduce dataframe size\n",
    "df_final = reduce_mem_usage(df_final)\n",
    "event_name = reduce_mem_usage(event_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unwanted dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_date=pd.DataFrame()\n",
    "calendar=pd.DataFrame()\n",
    "sell_prices=pd.DataFrame()\n",
    "sales_train_validation=pd.DataFrame()\n",
    "sales_train=pd.DataFrame()\n",
    "day_d=pd.DataFrame()\n",
    "sales_date=pd.DataFrame()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#TEST IF MODEL IS PREDICTING \n",
    "######################################\n",
    "historic_data = df_final[df_final['id'].isin(df_final.id.unique()[:1000].tolist())]\n",
    "historic_data = historic_data.rename(columns={'date':'ds'})\n",
    "######################################\n",
    "lists_ids = historic_data['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_df(lists_ids):\n",
    "    df = historic_data.loc[historic_data['id']==lists_ids]\n",
    "    df = df[['ds','y']]\n",
    "    return df\n",
    "\n",
    "def prophecy(lists_ids):\n",
    "    hist_data = forecast_df(lists_ids)\n",
    "    model = Prophet(uncertainty_samples=False,\n",
    "                    holidays = event_name)\n",
    "    \n",
    "    model.fit(hist_data)\n",
    "    build_forecast = model.make_future_dataframe(periods=28,freq='D',include_history=False)\n",
    "    forecast = model.predict(build_forecast)\n",
    "    \n",
    "    forecast[\"yhat\"] = (inv_boxcox(forecast[\"yhat\"], lamb)-1).round()\n",
    "    forecast_array = np.append(np.array([lists_ids]),forecast['yhat'].values.transpose())\n",
    "    return forecast_array\n",
    "\n",
    "#use multiple processing in code\n",
    "from multiprocessing import Pool, cpu_count\n",
    "print(f'Parallelism on {cpu_count()} CPU')\n",
    "\n",
    "start_time = time.time()\n",
    "forecast_array = []\n",
    "with Pool(cpu_count()) as p:\n",
    "    predictions = list(tqdm.tqdm(p.imap_unordered(prophecy, lists_ids),total=len(lists_ids)))\n",
    "    \n",
    "submission_df = pd.DataFrame(predictions)\n",
    "submission_df = submission_df.fillna(0)\n",
    "#submission_df.columns = submission_columns\n",
    "#submission_df.to_csv('submission1.csv', header='column_names', index=False)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baysian_forecast_df(lists_ids):\n",
    "    df = historic_data.loc[historic_data['id']==lists_ids]\n",
    "    return df\n",
    "\n",
    "def baysian_forecast(lists_ids):\n",
    "    hist = baysian_forecast_df(lists_ids)\n",
    "    hist_data = hist['y'].values\n",
    "    linear_trend = trend(degree=1, discount=0.95, name='linear_trend', w=100)\n",
    "    # weekly seasonality\n",
    "    seasonal52 = seasonality(period=52, discount=0.99, name='seasonal52', w=1.0)\n",
    "    # Build a simple dlm\n",
    "    simple_dlm = dlm(hist_data) + linear_trend + seasonal52 \n",
    "    # Fit the model\n",
    "    simple_dlm.fit()\n",
    "    forecast = simple_dlm.predictN(date=(len(hist_data) - 1), N=28)[0]\n",
    "    forecast = (inv_boxcox(forecast, lamb).round()-1)\n",
    "    #forecast = forecast.replace(np.inf, np.nan).replace(-np.inf, np.nan)\n",
    "    #forecast = forecast.fillna(0)\n",
    "    baysian_forecast_array = np.append(np.array([lists_ids]),forecast)\n",
    "    return baysian_forecast_array\n",
    "\n",
    "#use multiple processing in code\n",
    "from multiprocessing import Pool, cpu_count\n",
    "print(f'Parallelism on {cpu_count()} CPU')\n",
    "\n",
    "start_time = time.time()\n",
    "forecast_array = []\n",
    "with Pool(10) as p:\n",
    "    predictions = list(tqdm.tqdm(p.imap_unordered(baysian_forecast, lists_ids),total=len(lists_ids)))\n",
    "    #predictions = list(p.imap_unordered(baysian_forecast, lists_ids))\n",
    "    \n",
    "#submission_df_baysian = pd.DataFrame(predictions)\n",
    "#submission_df_df_baysian.columns = submission_columns\n",
    "#submission_df_df_baysian.to_csv('submission.csv', header='column_names', index=False)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv'))\n",
    "submission_columns=sample_submission.columns\n",
    "submission_df_baysian.columns = submission_columns\n",
    "submission_df.columns = submission_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = submission_df.melt(id_vars=[\"id\"], \n",
    "        var_name=\"day\", \n",
    "        value_name=\"prophet_forecast_sales_units\")\n",
    "\n",
    "submission_df_baysian = submission_df_baysian.melt(id_vars=[\"id\"], \n",
    "        var_name=\"day\", \n",
    "        value_name=\"baysian_forecast_sales_units\")\n",
    "\n",
    "combined_forecast_df = submission_df.merge(submission_df_baysian, on=['id','day'], how ='inner')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
