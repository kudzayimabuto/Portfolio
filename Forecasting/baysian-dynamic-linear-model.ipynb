{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Dynamic Linear Modelling with Multiple Processing\n",
    "\n",
    "Bayesian dynamic linear model is a promising method for time series data analysis and short-term forecasting. I used the model a few year ago in an attempt to sole a kaggle competition for the M5 Forecasting competition. However due to the limitations in time the model could only forecast 50% of the data before the cluster expired. A lot could be done to optimize the run like removing backawards and forward components of the forecating. this however sacrifices the accuracy and maximizes the runtime. This notebook utilizes multiple processing to parallelize the workload across multiple model keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### install pydlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pydlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pydlm import dlm, trend, seasonality\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import tqdm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function reduces dataframe size to keep the notebook from breaking when memory is full\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and transform data\n",
    "sales_train_validation = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv'))\n",
    "calendar = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv'))\n",
    "sell_prices = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sell_prices.csv'))\n",
    "submission_sample = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv'))\n",
    "\n",
    "\n",
    "sell_prices['id'] = sell_prices.item_id+'_'+ sell_prices.store_id+'_validation'\n",
    "ex_columns = ['item_id','dept_id','cat_id','store_id','state_id']\n",
    "sales_train_validation = reduce_mem_usage(sales_train_validation.drop(ex_columns, axis = 1))\n",
    "sales_train = reduce_mem_usage(sales_train_validation.melt(id_vars=[\"id\"], \n",
    "        var_name=\"d\", \n",
    "        value_name=\"sales_units\"))\n",
    "\n",
    "\n",
    "day_d = reduce_mem_usage(calendar[['date','d','wm_yr_wk']])\n",
    "sales_date = reduce_mem_usage(sales_train.merge(day_d, on = 'd', how = 'left'))\n",
    "sell_prices = reduce_mem_usage(sell_prices[['id','sell_price','wm_yr_wk']])\n",
    "\n",
    "df_final = reduce_mem_usage(sales_date.merge(sell_prices, on=['id','wm_yr_wk'], how = 'left'))\n",
    "df_final['y'] = df_final['sales_units']\n",
    "x_trans, lamb = boxcox(df_final['y']+1)\n",
    "df_final['y'] = x_trans\n",
    "\n",
    "#create holidays data frame\n",
    "\n",
    "event_name = calendar[['event_name_1','date']].dropna(axis = 0)\n",
    "event_name.columns = ['holiday','ds']\n",
    "event_name['lower_window'] = 0\n",
    "event_name['upper_window'] = 1\n",
    "#reduce dataframe size\n",
    "#Limit the data to at least 1 years of data\n",
    "min_date = pd.to_datetime(df_final['date'].max()) - datetime.timedelta(366)\n",
    "historic_data = df_final[df_final['date'] >= min_date.strftime(\"%Y-%m-%d\")]\n",
    "historic_data = reduce_mem_usage(historic_data)\n",
    "event_name = reduce_mem_usage(event_name)\n",
    "submission_columns = submission_sample.columns\n",
    "lists_ids = historic_data['id'].unique()\n",
    "#remove unwanted dfs\n",
    "sales_date=pd.DataFrame()\n",
    "calendar=pd.DataFrame()\n",
    "sell_prices=pd.DataFrame()\n",
    "sales_train_validation=pd.DataFrame()\n",
    "sales_train=pd.DataFrame()\n",
    "day_d=pd.DataFrame()\n",
    "sales_date=pd.DataFrame()\n",
    "df_final=pd.DataFrame()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forcasting functions\n",
    "def forecast_df(lists_ids):\n",
    "    df = historic_data.loc[historic_data['id']==lists_ids]\n",
    "    return df\n",
    "\n",
    "def baysian_forecast(lists_ids):\n",
    "    hist = forecast_df(lists_ids)\n",
    "    hist_data = hist['y'].values\n",
    "    linear_trend = trend(degree=1, discount=0.95, name='linear_trend', w=100)\n",
    "    # weekly seasonality\n",
    "    seasonal52 = seasonality(period=52, discount=0.99, name='seasonal52', w=1.0)\n",
    "    # Build a simple dlm\n",
    "    simple_dlm = dlm(hist_data) + linear_trend + seasonal52 \n",
    "    # Fit the model\n",
    "    simple_dlm.fit()\n",
    "    forecast = simple_dlm.predictN(date=(len(hist_data) - 1), N=28)[0]\n",
    "    forecast = (inv_boxcox(forecast, lamb).round()-1)\n",
    "    forecast = forecast.replace(np.inf, np.nan).replace(-np.inf, np.nan).replace(-0, 0).replace(np.nan, 0)\n",
    "    forecast = forecast.fillna(0)\n",
    "    forecast_array = np.append(np.array([lists_ids]),forecast)\n",
    "    return forecast_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use multiple processing in code\n",
    "from multiprocessing import Pool, cpu_count\n",
    "print(f'Parallelism on {cpu_count()} CPU')\n",
    "\n",
    "start_time = time.time()\n",
    "forecast_array = []\n",
    "with Pool(10) as p:\n",
    "    predictions = list(p.imap_unordered(baysian_forecast, lists_ids))\n",
    "    \n",
    "submission_df = pd.DataFrame(predictions)\n",
    "submission_df.columns = submission_columns\n",
    "submission_df.to_csv('submission.csv', header='column_names', index=False)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
